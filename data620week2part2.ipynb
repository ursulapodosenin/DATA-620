{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-21T13:57:52.401928Z",
     "iopub.status.busy": "2025-06-21T13:57:52.401595Z",
     "iopub.status.idle": "2025-06-21T13:57:55.495237Z",
     "shell.execute_reply": "2025-06-21T13:57:55.493739Z",
     "shell.execute_reply.started": "2025-06-21T13:57:52.401893Z"
    }
   },
   "source": [
    "DATA 620 Assignment Week 2 Part 2\n",
    "CUNY Data 620 - Web Analytics, Summer 2025\n",
    "\n",
    "Prof: Alain Ledon\n",
    "\n",
    "Members: Ahm Hamza, Ali Ahmed, Nilsa Bermudez, Ursula Podosenin\n",
    "\n",
    "Assignment\n",
    "Centrality measures can be used to predict (positive or negative) outcomes for a node. Your task in this week’s assignment is to identify an interesting set of network data that is available on the web (either through web scraping or web APIs) that could be used for analyzing and comparing centrality measures across nodes. As an additional constraint, there should be at least one categorical variable available for each node (such as “Male” or “Female”; “Republican”, “Democrat,” or “Undecided”, etc.)\n",
    "\n",
    "In addition to identifying your data source, you should create a high level plan that describes how you would load the data for analysis, and describe a hypothetical outcome that could be predicted from comparing degree centrality across categorical groups. For this week’s assignment, you are not required to actually load or analyze the data. Please see also Project 1 below.\n",
    "\n",
    "You may work in a small group on the assignment. You should post your document to GitHub by end of day on Sunday 6/22.\n",
    "\n",
    "Solution\n",
    "Data\n",
    "We will be using data from the Kaggle. Data downloaded from Kaggle - 116th Congress members. The data consists of 443 nodes and 47370 edges.\n",
    "The data is stored in a \".csv\" file and is downloadable from Kaggle. \n",
    "\n",
    "High Level Plan\n",
    "We will download the csv files from the source page (or put on github),and then load the .csv file into a Jupyter notebook. From there we will use the networkx package to do the analysis.  We will calculate the degree and eigenvector centrality.\n",
    "\n",
    "Conclusion\n",
    "This assignment outlines a clear plan for analyzing centrality measures using a network dataset of the 116th U.S. Congress from Kaggle. With categorical variables like political affiliation available, out goal is to explore how degree and eigenvector centrality differ across groups, such as Democrats and Republicans. This could help predict influence or connectivity within the legislative network. The data will be processed using NetworkX in a Jupyter notebook, setting the foundation for information into the structural roles of individuals in the network.\n",
    "\n",
    "\n",
    "\n",
    "Citation\n",
    "Kaggle - https://www.kaggle.com/datasets/aavigan/house-of-representatives-congress-116\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
